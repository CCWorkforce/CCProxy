OPENAI_API_KEY=<your openrouter api key>
BIG_MODEL_NAME=gpt-5-2025-08-07
SMALL_MODEL_NAME=gpt-5-mini-2025-08-07
LOG_LEVEL=DEBUG # could be DEBUG, INFO, ERROR, WARNING
LOG_PRETTY_CONSOLE=True
ERROR_LOG_FILE_PATH=error.jsonl
OPENAI_BASE_URL=https://api.openai.com/v1

IS_LOCAL_DEPLOYMENT=True # Set to True if it's a local deployment, otherwise set it to False

# Guardrail / security defaults
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_BURST=30
SECURITY_HEADERS_ENABLED=true
ENABLE_HSTS=false
ENABLE_CORS=false
CORS_ALLOW_ORIGINS=http://localhost:8082,http://127.0.0.1:8082
CORS_ALLOW_METHODS=POST,OPTIONS
CORS_ALLOW_HEADERS=Authorization,Content-Type,X-Requested-With
ALLOWED_HOSTS=localhost,127.0.0.1
RESTRICT_BASE_URL=true
ALLOWED_BASE_URL_HOSTS=api.openai.com,openrouter.ai,api.deepseek.com
REDACT_LOG_FIELDS=openai_api_key,authorization
MAX_STREAM_SECONDS=600

# Caching and performance
CACHE_TOKEN_COUNTS_ENABLED=true
CACHE_TOKEN_COUNTS_TTL_S=300
CACHE_TOKEN_COUNTS_MAX=2048
CACHE_CONVERTERS_ENABLED=true
CACHE_CONVERTERS_MAX=256
STREAM_DEDUPE_ENABLED=true
METRICS_CACHE_ENABLED=true

# Token truncation
TRUNCATE_LONG_REQUESTS=true
TRUNCATION_CONFIG={"strategy": "oldest_first", "min_tokens": 100, "system_message_priority": true}

# Provider retry policy
PROVIDER_MAX_RETRIES=3
PROVIDER_RETRY_BASE_DELAY=1.0
PROVIDER_RETRY_JITTER=0.5
